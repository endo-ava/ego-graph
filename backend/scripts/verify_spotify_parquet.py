"""R2ä¸Šã®Spotifyå†ç”Ÿå±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œè¨¼ãƒ»ç¢ºèªã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã€‚

ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°ã®ç¢ºèªã¨ã€æœ€æ–°50ä»¶ã®å†ç”Ÿå±¥æ­´ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚
DuckDBã® httpfs æ‹¡å¼µã‚’ä½¿ç”¨ã—ã¦ã€R2ä¸Šã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç›´æ¥ã‚¯ã‚¨ãƒªã—ã¾ã™ã€‚

Usage:
    uv run python backend/scripts/verify_spotify_parquet.py
"""

import logging
import os
import sys

import duckdb
from tabulate import tabulate

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.getcwd())

from shared.config import Config

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format="%(message)s")
logger = logging.getLogger(__name__)


def verify_r2_data():
    """R2ä¸Šã®Parquetãƒ‡ãƒ¼ã‚¿ã‚’æ¤œè¨¼ã—ã€æœ€æ–°ã®å±¥æ­´ã‚’è¡¨ç¤ºã™ã‚‹ã€‚"""
    logger.info("ğŸ¦† Verifying EgoGraph R2 Data Lake...")

    try:
        config = Config.from_env()
    except Exception:
        logger.exception("Failed to load config")
        return

    if not config.duckdb or not config.duckdb.r2:
        logger.error("R2 configuration is missing.")
        return

    r2_conf = config.duckdb.r2
    conn = duckdb.connect(":memory:")

    try:
        # S3(R2) è¨­å®šã®é©ç”¨
        conn.execute("INSTALL httpfs; LOAD httpfs;")
        conn.execute(
            """
            CREATE SECRET (
                TYPE S3,
                KEY_ID ?,
                SECRET ?,
                REGION 'auto',
                ENDPOINT ?,
                URL_STYLE 'path'
            );
            """,
            [
                r2_conf.access_key_id,
                r2_conf.secret_access_key.get_secret_value(),
                r2_conf.endpoint_url.replace("https://", ""),
            ],
        )

        # Parquetãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³
        parquet_url = f"s3://{r2_conf.bucket_name}/{r2_conf.events_path}spotify/plays/**/*.parquet"

        # 1. ç·ä»¶æ•°ã®ç¢ºèª
        count = conn.execute(
            "SELECT COUNT(*) FROM read_parquet(?)", [parquet_url]
        ).fetchone()[0]
        logger.info(f"âœ… Connection successful. Total records in R2: {count}")

        if count == 0:
            logger.info("â„¹ï¸ R2 is empty. Run ingestion first.")
            return

        # 2. æœ€æ–°50ä»¶ã®æ›²åãƒªã‚¹ãƒˆè¡¨ç¤º (ã‚·ãƒ³ãƒ—ãƒ«è¡¨ç¤º)
        logger.info("\nğŸ“Š Latest 50 Tracks:")
        query_simple = """
            SELECT track_name, artist_names[1] as artist, played_at_utc
            FROM read_parquet(?)
            ORDER BY played_at_utc DESC
            LIMIT 50
        """
        df_simple = conn.execute(query_simple, [parquet_url]).df()

        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’1ã‹ã‚‰æŒ¯ã‚‹
        df_simple.index = df_simple.index + 1
        print(
            tabulate(
                df_simple[["track_name", "artist"]],
                headers=["#", "Track Name", "Artist"],
                tablefmt="simple",
            )
        )

        # 3. ç›´è¿‘5ä»¶ã®è©³ç´°è¡¨ç¤º (ãƒ‡ãƒãƒƒã‚°ç”¨)
        logger.info("\nğŸ” Detailed View (Latest 5):")
        query_detail = """
            SELECT played_at_utc, track_name, artist_names, album_name
            FROM read_parquet(?)
            ORDER BY played_at_utc DESC
            LIMIT 5
        """
        df_detail = conn.execute(query_detail, [parquet_url]).df()
        print(tabulate(df_detail, headers="keys", tablefmt="simple_grid"))

    except duckdb.IOException as e:
        if "No files found" in str(e):
            logger.warning("âš ï¸ No Parquet files found in the specified path.")
        else:
            logger.error(f"âŒ DuckDB IO Error: {e}")
    except Exception as e:
        logger.error(f"âŒ Unexpected Error: {e}")
    finally:
        conn.close()


if __name__ == "__main__":
    verify_r2_data()
